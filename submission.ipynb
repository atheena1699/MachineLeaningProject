{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T02:09:44.959763Z",
     "start_time": "2018-09-07T02:09:43.081242Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from random import sample,shuffle\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import model_selection\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import pipeline\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from scipy.sparse import csr_matrix,lil_matrix,identity\n",
    "\n",
    "import pandas\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T02:10:08.694930Z",
     "start_time": "2018-09-07T02:09:44.961847Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading rows: 100%|██████████| 20000/20000 [00:16<00:00, 1180.02it/s]\n",
      "converting to edges: 100%|██████████| 20000/20000 [00:06<00:00, 3093.86it/s]\n"
     ]
    }
   ],
   "source": [
    "### In[2]:\n",
    "random.seed(4)\n",
    "\n",
    "# Read in list of edges from csv\n",
    "def load_csv(fname=\"train.txt\"):\n",
    "    with open(fname) as file:\n",
    "        reader = csv.reader(file, delimiter=\"\\t\")\n",
    "        rows = []\n",
    "        for row in tqdm(reader, total=20000, desc=\"reading rows\"):\n",
    "            row = [int(el) for el in row]\n",
    "            source = row[0]\n",
    "            sinks = sorted(row[1:])\n",
    "            rows.append((source, sinks))\n",
    "            \n",
    "        rows.sort(key=lambda row: row[0])\n",
    "        \n",
    "        edges = []\n",
    "        for row in tqdm(rows, total=20000, desc=\"converting to edges\"):\n",
    "            source, sinks = row\n",
    "            edges += [(source, sink) for sink in sorted(sinks)]\n",
    "\n",
    "        return edges\n",
    "\n",
    "edges = load_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T02:10:15.547586Z",
     "start_time": "2018-09-07T02:10:08.699801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting edges\n",
      "splitting\n",
      "sorting\n",
      "getting\n",
      "adding negative cases\n",
      "known: 23973361, training: 60000, validation: 2000\n"
     ]
    }
   ],
   "source": [
    "print(\"sorting edges\")\n",
    "\n",
    "# Randomly generate new edges, based on a set of existing edges\n",
    "def random_edges(edges, n):\n",
    "    return [(random.choice(edges)[0], random.choice(edges)[1]) for i in range(n)]\n",
    "\n",
    "n_train = 60000\n",
    "n_val = 2000\n",
    "\n",
    "print(\"splitting\")\n",
    "# Keep 1000 edges for training and validation\n",
    "# the rest is \"prior knowledge\"\n",
    "kn, ukn = next(model_selection.ShuffleSplit(test_size=(n_train + n_val)//2).split(edges))\n",
    "print(\"sorting\")\n",
    "kn.sort()\n",
    "ukn.sort()\n",
    "print(\"getting\")\n",
    "edges_known = [edges[i] for i in kn]\n",
    "edges_unknown = [edges[i] for i in ukn]\n",
    "# edges_known, edges_unknown = model_selection.train_test_split(edges, test_size=(n_train + n_val)//2)\n",
    "\n",
    "# Keep 200 of the 1000 for validation\n",
    "edges_train, edges_val = model_selection.train_test_split(edges_unknown, test_size=n_val//2)\n",
    "\n",
    "print(\"adding negative cases\")\n",
    "edges_train = edges_train + random_edges(edges_known, len(edges_train))\n",
    "edges_val   = edges_val + random_edges(edges_val, len(edges_val))\n",
    "shuffle(edges_train)\n",
    "shuffle(edges_val)\n",
    "\n",
    "print(\"known: {}, training: {}, validation: {}\".format(len(edges_known), len(edges_train), len(edges_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T02:12:20.088333Z",
     "start_time": "2018-09-07T02:10:15.549556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting known edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing known edges: 100%|██████████| 23973361/23973361 [01:15<00:00, 318937.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transposing known\n",
      "processing unknown edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing unknown edges: 100%|██████████| 31000/31000 [00:00<00:00, 285129.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding known to unknown\n"
     ]
    }
   ],
   "source": [
    "MAX_ID=4867135\n",
    "def process(edges, desc=\"\", max_id=MAX_ID):\n",
    "    adjacency = lil_matrix((max_id+1, max_id+1))\n",
    "    for (source, sink) in tqdm(edges, desc=\"processing \" + desc + \" edges\"):\n",
    "        adjacency[source, sink] = 1\n",
    "    return adjacency.tocsr(), adjacency\n",
    "\n",
    "print(\"starting known edges\")\n",
    "adjacency_known, adjacency_known_lil = process(edges_known, \"known\")\n",
    "print(\"transposing known\")\n",
    "adjacency_t_known = adjacency_known.transpose(copy=True)\n",
    "adjacency_t_known_lil = adjacency_known_lil.transpose(copy=True)\n",
    "print(\"processing unknown edges\")\n",
    "adjacency_unknown, _ = process(edges_unknown, \"unknown\")\n",
    "print(\"adding known to unknown\")\n",
    "adjacency = adjacency_known + adjacency_unknown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T02:12:20.868755Z",
     "start_time": "2018-09-07T02:12:20.090485Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " features 0:   0%|          | 0/1 [00:00<?, ?it/s]/usr/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      " features 0: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features before polynomial interactions: 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_a_followees': 51725,\n",
       " 'n_b_followees': 0,\n",
       " 'n_a_followers': 976,\n",
       " 'n_b_followers': 146,\n",
       " 'a_followees`intersection_count`b_followees': 0,\n",
       " 'a_followees`intersection_count`a_followers': 931,\n",
       " 'a_followees`intersection_count`b_followers': 117,\n",
       " 'b_followees`intersection_count`a_followees': 0,\n",
       " 'b_followees`intersection_count`a_followers': 0,\n",
       " 'b_followees`intersection_count`b_followers': 0,\n",
       " 'a_followers`intersection_count`a_followees': 931,\n",
       " 'a_followers`intersection_count`b_followees': 0,\n",
       " 'a_followers`intersection_count`b_followers': 115,\n",
       " 'b_followers`intersection_count`a_followees': 117,\n",
       " 'b_followers`intersection_count`b_followees': 0,\n",
       " 'b_followers`intersection_count`a_followers': 115,\n",
       " 'n_a_followees/n_b_followees': 51725.0,\n",
       " 'n_a_followees/n_a_followers': 52.94268167860798,\n",
       " 'n_a_followees/n_b_followers': 351.8707482993197,\n",
       " 'n_b_followees/n_a_followees': 0.0,\n",
       " 'n_b_followees/n_a_followers': 0.0,\n",
       " 'n_b_followees/n_b_followers': 0.0,\n",
       " 'n_a_followers/n_a_followees': 0.01886865406178711,\n",
       " 'n_a_followers/n_b_followees': 976.0,\n",
       " 'n_a_followers/n_b_followers': 6.639455782312925,\n",
       " 'n_b_followers/n_a_followees': 0.002822565054324711,\n",
       " 'n_b_followers/n_b_followees': 146.0,\n",
       " 'n_b_followers/n_a_followers': 0.14943705220061412,\n",
       " 'a_followees`jaccard`b_followees': 0.0,\n",
       " 'a_followees`jaccard`a_followers': 0.01798338806258451,\n",
       " 'a_followees`jaccard`b_followers': 0.0022606948255207327,\n",
       " 'b_followees`jaccard`a_followees': 0.0,\n",
       " 'b_followees`jaccard`a_followers': 0.0,\n",
       " 'b_followees`jaccard`b_followers': 0.0,\n",
       " 'a_followers`jaccard`a_followees': 0.01798338806258451,\n",
       " 'a_followers`jaccard`b_followees': 0.0,\n",
       " 'a_followers`jaccard`b_followers': 0.11420059582919563,\n",
       " 'b_followers`jaccard`a_followees': 0.0022606948255207327,\n",
       " 'b_followers`jaccard`b_followees': 0.0,\n",
       " 'b_followers`jaccard`a_followers': 0.11420059582919563,\n",
       " 'a_followees`cosine`b_followees': 0.0,\n",
       " 'a_followees`cosine`a_followers': 4.055461221121535,\n",
       " 'a_followees`cosine`b_followers': 0.5137165430725769,\n",
       " 'b_followees`cosine`a_followees': 0.0,\n",
       " 'b_followees`cosine`a_followers': 0.0,\n",
       " 'b_followees`cosine`b_followers': 0.0,\n",
       " 'a_followers`cosine`a_followees': 4.055461221121535,\n",
       " 'a_followers`cosine`b_followees': 0.0,\n",
       " 'a_followers`cosine`b_followers': 3.4332182456525597,\n",
       " 'b_followers`cosine`a_followees': 0.5137165430725769,\n",
       " 'b_followers`cosine`b_followees': 0.0,\n",
       " 'b_followers`cosine`a_followers': 3.4332182456525597,\n",
       " 'mean(sample_followees_followee_jaccards)': nan,\n",
       " 'mean(sample_followees_follower_jaccards)': 0.15745617111343593,\n",
       " 'mean(sample_followees_followee_cosines)': nan,\n",
       " 'mean(sample_followees_follower_cosines)': 2.3036663398764814,\n",
       " 'mean(sample_followees_followee_counts)': 1010.1,\n",
       " 'mean(sample_followees_follower_counts)': 147.4,\n",
       " 'mean(sample_followers_followee_jaccards)': 0.10452572655475448,\n",
       " 'mean(sample_followers_follower_jaccards)': 0.22119206522610235,\n",
       " 'mean(sample_followers_followee_cosines)': 29.503422395827346,\n",
       " 'mean(sample_followers_follower_cosines)': 7.709076414171387,\n",
       " 'mean(sample_followers_followee_counts)': 36747.2,\n",
       " 'mean(sample_followers_follower_counts)': 812.2,\n",
       " 'std(sample_followees_followee_jaccards)': nan,\n",
       " 'std(sample_followees_follower_jaccards)': 0.07405653897625261,\n",
       " 'std(sample_followees_followee_cosines)': nan,\n",
       " 'std(sample_followees_follower_cosines)': 1.1823330896597661,\n",
       " 'std(sample_followees_followee_counts)': 2046.2305075430772,\n",
       " 'std(sample_followees_follower_counts)': 136.55709428660234,\n",
       " 'std(sample_followers_followee_jaccards)': 0.06913838287255186,\n",
       " 'std(sample_followers_follower_jaccards)': 0.08917000010637546,\n",
       " 'std(sample_followers_followee_cosines)': 22.319816990573894,\n",
       " 'std(sample_followers_follower_cosines)': 3.4625226129380837,\n",
       " 'std(sample_followers_followee_counts)': 32746.138364088063,\n",
       " 'std(sample_followers_follower_counts)': 496.6696688947293,\n",
       " 'var(sample_followees_followee_jaccards)': nan,\n",
       " 'var(sample_followees_follower_jaccards)': 0.005484370965141223,\n",
       " 'var(sample_followees_followee_cosines)': nan,\n",
       " 'var(sample_followees_follower_cosines)': 1.3979115349044087,\n",
       " 'var(sample_followees_followee_counts)': 4187059.289999999,\n",
       " 'var(sample_followees_follower_counts)': 18647.840000000004,\n",
       " 'var(sample_followers_followee_jaccards)': 0.004780115986231573,\n",
       " 'var(sample_followers_follower_jaccards)': 0.007951288918970999,\n",
       " 'var(sample_followers_followee_cosines)': 498.1742304927111,\n",
       " 'var(sample_followers_follower_cosines)': 11.989062845107574,\n",
       " 'var(sample_followers_followee_counts)': 1072309577.76,\n",
       " 'var(sample_followers_follower_counts)': 246680.76,\n",
       " 'median(sample_followees_followee_jaccards)': nan,\n",
       " 'median(sample_followees_follower_jaccards)': 0.16034126648828803,\n",
       " 'median(sample_followees_followee_cosines)': nan,\n",
       " 'median(sample_followees_follower_cosines)': 2.293485592052431,\n",
       " 'median(sample_followees_followee_counts)': 0.0,\n",
       " 'median(sample_followees_follower_counts)': 96.0,\n",
       " 'median(sample_followers_followee_jaccards)': 0.09901974048079687,\n",
       " 'median(sample_followers_follower_jaccards)': 0.21154644880381554,\n",
       " 'median(sample_followers_followee_cosines)': 25.654213439438905,\n",
       " 'median(sample_followers_follower_cosines)': 6.957291919825709,\n",
       " 'median(sample_followers_followee_counts)': 27314.5,\n",
       " 'median(sample_followers_follower_counts)': 645.5,\n",
       " 'min(sample_followees_followee_jaccards)': 0.0,\n",
       " 'min(sample_followees_follower_jaccards)': 0.03225806451612903,\n",
       " 'min(sample_followees_followee_cosines)': 0.0,\n",
       " 'min(sample_followees_follower_cosines)': 0.3952847075210474,\n",
       " 'min(sample_followees_followee_counts)': 0,\n",
       " 'min(sample_followees_follower_counts)': 14,\n",
       " 'min(sample_followers_followee_jaccards)': 0.005121170553269319,\n",
       " 'min(sample_followers_follower_jaccards)': 0.03488372093023256,\n",
       " 'min(sample_followers_followee_cosines)': 1.1944127349695983,\n",
       " 'min(sample_followers_follower_cosines)': 1.1015821104517882,\n",
       " 'min(sample_followers_followee_counts)': 3230,\n",
       " 'min(sample_followers_follower_counts)': 92,\n",
       " 'max(sample_followees_followee_jaccards)': 0.0,\n",
       " 'max(sample_followees_follower_jaccards)': 0.29743589743589743,\n",
       " 'max(sample_followees_followee_cosines)': 0.0,\n",
       " 'max(sample_followees_follower_cosines)': 4.581611733630265,\n",
       " 'max(sample_followees_followee_counts)': 5778,\n",
       " 'max(sample_followees_follower_counts)': 420,\n",
       " 'max(sample_followers_followee_jaccards)': 0.22508055340842967,\n",
       " 'max(sample_followers_follower_jaccards)': 0.3403707518022657,\n",
       " 'max(sample_followers_followee_cosines)': 69.00342534696263,\n",
       " 'max(sample_followers_follower_cosines)': 12.955804185082947,\n",
       " 'max(sample_followers_followee_counts)': 101384,\n",
       " 'max(sample_followers_follower_counts)': 1627,\n",
       " 'follows_back': 0.0,\n",
       " 'followee_friends_that_are_followers': 117,\n",
       " 'followee_friends_that_are_followees': 0,\n",
       " 'follower_friends_that_are_followers': 115,\n",
       " 'follower_friends_that_are_followees': 115}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def friends_following(source, sink, friends_are_followers=False):\n",
    "    # Get who source follows, and who follows sink, do a dot product to count\n",
    "    # the number of elements where both are non-zero\n",
    "    if friends_are_followers:\n",
    "        return len(set(adjacency_t_known_lil[source].tocsr().indices).intersection(adjacency_t_known_lil[sink].tocsr().indices))\n",
    "    else:\n",
    "        return len(set(adjacency_known[source].tocsr().indices).intersection(adjacency_t_known_lil[sink].tocsr().indices))\n",
    "\n",
    "def jaccard(a, b):\n",
    "    a = set(a.indices)\n",
    "    b = set(b.indices)\n",
    "    union = len(a.union(b))\n",
    "    if union == 0:\n",
    "        return np.nan\n",
    "    return len(a.intersection(b)) / union\n",
    "\n",
    "def cosine(a, b):\n",
    "    return a.dot(b.transpose())[0,0] / np.sqrt(a.count_nonzero() + b.count_nonzero())\n",
    "    return cosine_similarity(a, b)[0, 0]\n",
    "\n",
    "def interactions(features, func=np.multiply, infix=\"*\"):\n",
    "    return { k1 + infix + k2: func(v1, v2) for k1,v1 in features.items() for k2,v2 in features.items() if k1 != k2 }\n",
    "\n",
    "def derived(features, func=np.reciprocal, prefix = \"1/\", postfix = \"\"):\n",
    "    return { prefix + k + postfix: func(v) for k,v in features.items()}\n",
    "\n",
    "def safe_div(a, b):\n",
    "    return a / (b + 1)\n",
    "\n",
    "def do_sample(sparse, n):\n",
    "    rows, cols = sparse.nonzero()\n",
    "    els = list(cols)\n",
    "    if n >= len(els):\n",
    "        return els\n",
    "    return sample(els, n)\n",
    "\n",
    "def intersection_count(a, b):\n",
    "    return len(set(a.indices).intersection(set(b.indices)))\n",
    "\n",
    "def safe_arr_op(f):\n",
    "    def safe_f(arr):\n",
    "        if len(arr):\n",
    "            return f(arr)\n",
    "        return np.nan\n",
    "    return safe_f\n",
    "\n",
    "# Encode the training \"X\" data and \"y\" value of a data point (edge)\n",
    "# a is source, b is sink\n",
    "def make_row(a, b):\n",
    "    a_followees = adjacency_known[a]\n",
    "    b_followees = adjacency_known[b]\n",
    "    a_followers = adjacency_t_known_lil[a].tocsr()\n",
    "    b_followers = adjacency_t_known_lil[b].tocsr()\n",
    "    \n",
    "    friends = {\n",
    "        \"a_followees\": a_followees,\n",
    "        \"b_followees\": b_followees,\n",
    "        \"a_followers\": a_followers,\n",
    "        \"b_followers\": b_followers,\n",
    "    }\n",
    "    \n",
    "    counts = { \"n_\" + key: val.count_nonzero() for (key, val) in friends.items() }\n",
    "    count_ratios = interactions(counts, func=safe_div, infix=\"/\")\n",
    "    \n",
    "    intersection_counts = interactions(friends, func=intersection_count, infix=\"`intersection_count`\")\n",
    "\n",
    "    jaccards = interactions({\n",
    "        \"a_followees\": a_followees,\n",
    "        \"b_followees\": b_followees,\n",
    "        \"a_followers\": a_followers,\n",
    "        \"b_followers\": b_followers\n",
    "    }, func=jaccard, infix=\"`jaccard`\")\n",
    "\n",
    "    cosines = interactions({\n",
    "        \"a_followees\": a_followees,\n",
    "        \"b_followees\": b_followees,\n",
    "        \"a_followers\": a_followers,\n",
    "        \"b_followers\": b_followers\n",
    "    }, func=cosine, infix=\"`cosine`\")\n",
    "\n",
    "    sample_followees = do_sample(a_followees, 5)\n",
    "    followees_followees = [adjacency_known[followee] for followee in sample_followees]\n",
    "    followees_followers = [adjacency_t_known_lil[followee].tocsr() for followee in sample_followees]\n",
    "    sample_followees_followee_jaccards = [jaccard(b_followees, followee) for followee in followees_followees]\n",
    "    sample_followees_follower_jaccards = [jaccard(b_followers, follower) for follower in followees_followers]\n",
    "    sample_followees_followee_cosines  = [cosine(b_followees,  followee) for followee in followees_followees]\n",
    "    sample_followees_follower_cosines  = [cosine(b_followers,  follower) for follower in followees_followers]\n",
    "    sample_followees_followee_counts   = [followee.count_nonzero() for followee in followees_followees]\n",
    "    sample_followees_follower_counts   = [follower.count_nonzero() for follower in followees_followers]\n",
    "\n",
    "    sample_followers = do_sample(b_followers, 5)\n",
    "    followers_followees = [adjacency_known[follower] for follower in sample_followers]\n",
    "    followers_followers = [adjacency_t_known_lil[follower].tocsr() for follower in sample_followers]\n",
    "    sample_followers_followee_jaccards = [jaccard(a_followees, followee) for followee in followers_followees]\n",
    "    sample_followers_follower_jaccards = [jaccard(a_followers, follower) for follower in followers_followers]\n",
    "    sample_followers_followee_cosines  = [cosine(a_followees,  followee) for followee in followers_followees]\n",
    "    sample_followers_follower_cosines  = [cosine(a_followers,  follower) for follower in followers_followers]\n",
    "    sample_followers_followee_counts   = [followee.count_nonzero() for followee in followers_followees]\n",
    "    sample_followers_follower_counts   = [follower.count_nonzero() for follower in followers_followers]\n",
    "\n",
    "    sampled = {\n",
    "        func_name + \"(\" + arr_name + \")\": func(arr)\n",
    "        for func_name, func in [(\"mean\", np.mean), (\"std\", np.std), (\"var\", np.var), (\"median\", np.median), (\"min\", safe_arr_op(np.nanmin)), (\"max\", safe_arr_op(np.nanmax))]\n",
    "        for arr_name, arr in [\n",
    "            (\"sample_followees_followee_jaccards\", sample_followees_followee_jaccards),\n",
    "            (\"sample_followees_follower_jaccards\", sample_followees_follower_jaccards),\n",
    "            (\"sample_followees_followee_cosines\",  sample_followees_followee_cosines),\n",
    "            (\"sample_followees_follower_cosines\",  sample_followees_follower_cosines),\n",
    "            (\"sample_followees_followee_counts\",   sample_followees_followee_counts),\n",
    "            (\"sample_followees_follower_counts\",   sample_followees_follower_counts),\n",
    "            (\"sample_followers_followee_jaccards\", sample_followers_followee_jaccards),\n",
    "            (\"sample_followers_follower_jaccards\", sample_followers_follower_jaccards),\n",
    "            (\"sample_followers_followee_cosines\",  sample_followers_followee_cosines),\n",
    "            (\"sample_followers_follower_cosines\",  sample_followers_follower_cosines),\n",
    "            (\"sample_followers_followee_counts\",   sample_followers_followee_counts),\n",
    "            (\"sample_followers_follower_counts\",   sample_followers_follower_counts),\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    followee_friends_that_are_followers = friends_following(a, b)\n",
    "    followee_friends_that_are_followees = friends_following(b, a)\n",
    "    follower_friends_that_are_followers = friends_following(a, b, True)\n",
    "    follower_friends_that_are_followees = friends_following(b, a, True)\n",
    "    follows_back = adjacency_known[b, a]\n",
    "\n",
    "    return {\n",
    "        **counts,\n",
    "        **intersection_counts,\n",
    "        **count_ratios,\n",
    "        **jaccards,\n",
    "        **cosines,\n",
    "        **sampled,\n",
    "        \"follows_back\": follows_back,\n",
    "        \"followee_friends_that_are_followers\": followee_friends_that_are_followers,\n",
    "        \"followee_friends_that_are_followees\": followee_friends_that_are_followees,\n",
    "        \"follower_friends_that_are_followers\": follower_friends_that_are_followers,\n",
    "        \"follower_friends_that_are_followees\": follower_friends_that_are_followees,\n",
    "    }\n",
    "\n",
    "\n",
    "# Get the correct y value for a data point\n",
    "def get_y(source, sink, validation = False):\n",
    "    if validation:\n",
    "        return 1\n",
    "    return 1 if adjacency[source, sink] else 0\n",
    "\n",
    "# Given a list of edges, create X and y matrices of features\n",
    "def get_features_(edges, pos, desc=\"\", validation=False):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for (source, sink) in tqdm(edges, desc=desc + \" features \" + str(pos), position=pos) if pos==0 else edges:\n",
    "        X_row = make_row(source, sink)\n",
    "        X.append(X_row)\n",
    "        y.append(get_y(source, sink, validation))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def do_row(edge):\n",
    "    return make_row(edge[0], edge[1])\n",
    "def do_y(edge):\n",
    "    return get_y(edge[0], edge[1])\n",
    "\n",
    "def chunks(l, n):\n",
    "    ret = [l[i*len(l)//n:(i+1)*len(l)//n] for i in range(n)]\n",
    "    assert(np.sum([len(chunk) for chunk in ret]) == len(l))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def do_chunk(chunk):\n",
    "    return get_features_(chunk[1], pos=chunk[0])\n",
    "\n",
    "def do_chunk_val(chunk):\n",
    "    return get_features_(chunk[1], pos=chunk[0])\n",
    "\n",
    "# Given a list of edges, create X and y matrices of features\n",
    "def get_features(edges, desc=\"\", validation=False):\n",
    "  \n",
    "    pool = mp.Pool()\n",
    "    X = []\n",
    "    y = []\n",
    "    edges_chunked = chunks(edges, 4)\n",
    "    for res in pool.map(do_chunk_val, enumerate(edges_chunked)) if validation else pool.map(do_chunk, enumerate(edges_chunked)):\n",
    "        X += res[0]\n",
    "        y += res[1]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Get some feature for a row, so we can see an example\n",
    "row = get_features_([edges_train[8]], pos=0)[0][0]\n",
    "n_features=len(row)\n",
    "\n",
    "print(\"number of features before polynomial interactions: {}\".format(n_features))\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T02:13:24.078004Z",
     "start_time": "2018-09-07T02:12:20.871203Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " features 0:   2%|▏         | 1/60 [00:00<00:33,  1.76it/s]/usr/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3194: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/usr/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:43: RuntimeWarning: All-NaN axis encountered\n",
      " features 0: 100%|██████████| 60/60 [00:39<00:00,  1.51it/s]\n",
      " features 0: 100%|██████████| 15/15 [00:19<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    get_features_(edges_train[:60], pos=0)\n",
    "%lprun -f test -f make_row -f jaccard -f cosine test()\n",
    "\n",
    "get_features(edges_train[:60])[0][0]\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-07T02:09:43.104Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " features 0:   0%|          | 0/15000 [00:00<?, ?it/s]/usr/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      " features 0:   0%|          | 1/15000 [00:01<4:19:30,  1.04s/it]/usr/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:43: RuntimeWarning: All-NaN axis encountered\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:43: RuntimeWarning: All-NaN axis encountered\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3194: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/usr/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:43: RuntimeWarning: All-NaN axis encountered\n",
      " features 0:   0%|          | 2/15000 [00:02<4:38:38,  1.11s/it]/usr/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:43: RuntimeWarning: All-NaN axis encountered\n",
      " features 0:   0%|          | 4/15000 [00:04<5:10:51,  1.24s/it]/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3194: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      " features 0:   0%|          | 8/15000 [00:09<4:49:33,  1.16s/it]/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " features 0:   0%|          | 9/15000 [00:10<5:01:05,  1.21s/it]/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3194: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      " features 0:   0%|          | 50/15000 [01:06<5:32:56,  1.34s/it]/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3194: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      " features 0:   2%|▏         | 233/15000 [05:38<5:57:04,  1.45s/it]"
     ]
    }
   ],
   "source": [
    "random.seed(5)\n",
    "# Make our final training data, by sampling from existing edges, and adding in other random edges\n",
    "# We sample a small subset from our training data for computational reasons\n",
    "X_train, y_train = get_features(edges_train, desc=\"train\")\n",
    "X_val, y_val = get_features(edges_val, desc=\"validation\")\n",
    "\n",
    "# Frequency count to check how unbalanced our classes are\n",
    "print(pandas.Series(y_train).value_counts())\n",
    "print(pandas.Series(y_val).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-07T02:09:43.106Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "def inv(X):\n",
    "    return np.hstack([X, 1 / (X + 1), X==0, ])\n",
    "\n",
    "def add_is_zero(X):\n",
    "    return np.hstack([X, X==0])\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vec', feature_extraction.DictVectorizer(sparse=False)),\n",
    "    ('impute', preprocessing.Imputer()),\n",
    "#     ('booleans', preprocessing.FunctionTransformer(add_is_zero)),\n",
    "    ('norm', preprocessing.StandardScaler()),\n",
    "#     ('model', MLP(hidden_layer_sizes=n_features)),\n",
    "#     ('select', feature_selection.RFE(LR(), n_features_to_select=100, verbose=3)),\n",
    "    ('select', feature_selection.SelectKBest(k=100)),\n",
    "    ('model', MLP()),\n",
    "])\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(model, X_train, y_train, train_sizes=np.arange(0.05, 1.01, 0.05), cv=5)\n",
    "\n",
    "train_scores = [np.mean(scores) for scores in train_scores]\n",
    "val_scores = [np.mean(scores) for scores in val_scores]\n",
    "\n",
    "print(train_scores)\n",
    "print(val_scores)\n",
    "plt.plot(train_sizes, val_scores, 'b', label='test')\n",
    "plt.plot(train_sizes, train_scores, 'r', label='train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-07T02:09:43.108Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-07T02:09:43.110Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(3)\n",
    "# Check how we score against the validation set\n",
    "print(model.score(X_val, y_val))\n",
    "print(metrics.roc_auc_score(model.predict(X_val), y_val))\n",
    "print(metrics.classification_report(model.predict(X_val), y_val))\n",
    "\n",
    "# Check how many accurate predictions we have for each class\n",
    "print(confusion_matrix(model.predict(X_val), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-07T02:09:43.120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the test data, make predictions with a model, write to a new csv\n",
    "def make_submission(model, file_in=\"test-public.txt\", file_out=\"predictions.csv\"):\n",
    "    edges = []\n",
    "    with open(file_in) as file:\n",
    "        reader = csv.reader(file, delimiter=\"\\t\")\n",
    "        header = True\n",
    "        for row in reader:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            row = [int(el) for el in row]\n",
    "            id, source, sink = row\n",
    "            edges.append(tuple([source, sink]))\n",
    "            \n",
    "    X_test, _ = get_features(edges, desc=\"pred\", validation=True)\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "        \n",
    "    with open(file_out, 'w') as file:\n",
    "        writer = csv.writer(file, delimiter=\",\")\n",
    "        writer.writerow([\"Id\", \"Prediction\"])\n",
    "        for i in range(len(y_pred)):\n",
    "            writer.writerow([i+1, y_pred[i][1]])\n",
    "\n",
    "make_submission(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
